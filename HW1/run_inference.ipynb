{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc42d756-fe23-475f-b6c2-d3252047f0fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6002ea9c-8631-47ef-b57e-a090d59c5468",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(51, 32, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.drop = nn.Dropout(0.1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=(3, 3), stride=1, padding=1)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "\n",
    "        self.fc1 = nn.Linear(64 * 32 * 32, 256)\n",
    "        self.act3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(256, 18)\n",
    "        # self.softmax = nn.Softmax\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act1(self.conv1(x))\n",
    "        x = self.drop(x)\n",
    "        x = self.act2(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.reshape(-1, 64 * 32 * 32)\n",
    "        x = self.act3(self.fc1(x))\n",
    "        # x = self.softmax(self.fc2(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1236f139-a8a9-4f8a-864e-bb6c4f7be142",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CellData(Dataset):\n",
    "    def __init__(self, cells, cell_inds):\n",
    "        self.cells = cells\n",
    "        self.cell_inds = cell_inds\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.cell_inds)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.cells[index]\n",
    "        ind = self.cell_inds[index]\n",
    "        return ind, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6be68ae-2d8b-4337-946d-893233706ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(X):\n",
    "    for i in tqdm(range(X.shape[-1])):\n",
    "        X[..., i] = exposure.rescale_intensity(X[..., i], out_range=(-1, 1))\n",
    "        X[..., i] = exposure.equalize_adapthist(X[..., i])\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa67306d-99dc-4867-9557-513c12d4759f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_cells(X, y):\n",
    "    X = normalize(X)\n",
    "    cell_dict = {}\n",
    "    for i in tqdm(np.unique(y)):\n",
    "        img_x, img_y = np.where(cell_mask==i)\n",
    "        \n",
    "        if len(img_x)==0 or len(img_y)==0:\n",
    "            continue\n",
    "        cell = X[img_x, img_y]\n",
    "        img_x1, img_y1, img_x2, img_y2 = img_x.min(), img_y.min(), img_x.max(), img_y.max()\n",
    "        cell_mask = np.zeros((img_x2-img_x1, img_y2-img_y1))\n",
    "        cell_mask = (cell_mask[img_x1:img_x2, img_y1:img_y2]==i)\n",
    "        \n",
    "        cell_image = image[img_x1:img_x2, img_y1:img_y2]\n",
    "        cell_image = cell_image * np.repeat(np.expand_dims(cell_mask, axis=2), 51, axis=2)\n",
    "        \n",
    "        cell_image = cv2.resize(cell_image, (cell_size, cell_size))\n",
    "        cell_dict[i] = cell_image\n",
    "    return cell_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbc716bf-b1ad-4ad6-8a22-bd9128a9c5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference(X, y):\n",
    "    cell_dict = segment_cells(X, y)\n",
    "    cell_dataset = CellData(list(cell_dict.values()), list(cell_dict.keys()))\n",
    "    cell_loader = DataLoader(cell_dataset, batch_size=32, shuffle=True)\n",
    "    \n",
    "    pred_dict_\n",
    "    model = CNN()\n",
    "    model.double()\n",
    "    model.load_state_dict(torch.load(\"model_weights.pt\"))\n",
    "    model.eval()\n",
    "    \n",
    "    all_preds = []\n",
    "    all_inds = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for indices, inputs in tqdm(cell_loader):\n",
    "            inputs = inputs.permute(0, 3, 1, 2)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            all_inds.extend(indices.numpy())\n",
    "            all_preds.extend(predicted.numpy())\n",
    "\n",
    "    pred_dict = dict(zip(all_inds, all_preds))\n",
    "    return pred_dict\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
